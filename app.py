import os
import cv2
import json
import numpy as np
import streamlit as st
from google import genai
from google.genai import types
import requests
from dotenv import load_dotenv
from datetime import datetime
from ultralytics import YOLO
import plotly.express as px
import plotly.graph_objects as go
import feedparser
import pydeck as pdk
import graphviz
from tamper import store_evidence, verify_chain, get_evidence_count, publish_to_chain, generate_zk_proof, mint_sbt, SmartContract
from swarm import SwarmNode
import tempfile

# -----------------------------
# CONFIG & STYLE
# -----------------------------
st.set_page_config(
    page_title="GuardianAI | Intelligent Detection",
    page_icon="üåä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize Swarm
if "swarm_node" not in st.session_state:
    st.session_state.swarm_node = SwarmNode()
    st.session_state.swarm_node.start()

import pandas as pd
import time
import re
import PIL.Image
import io

def load_css():
    try:
        with open("style.css") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        pass

load_css()

# -----------------------------
# DEAD MAN'S SWITCH (App Side)
# -----------------------------
# DEAD MAN'S SWITCH (App Side)
# -----------------------------
HEARTBEAT_FILE = ".heartbeat" # Daemon writes this
OPERATOR_PULSE_FILE = ".operator_pulse" # App writes this

# Update Operator Pulse
with open(OPERATOR_PULSE_FILE, "w") as f:
    f.write(str(datetime.utcnow().timestamp()))

def check_security_status():
    """Checks if the security daemon is alive."""
    if os.path.exists(HEARTBEAT_FILE):
        try:
            with open(HEARTBEAT_FILE, 'r') as f:
                last_beat = float(f.read().strip())
            
            if (datetime.utcnow().timestamp() - last_beat) > 20: # 20s Clean buffer
                st.error("üö® CRITICAL SECURITY ALERT: DAEMON UNRESPONSIVE")
                st.markdown(
                    "<div style='position:fixed;top:0;left:0;width:100%;height:100%;background:rgba(255,0,0,0.9);z-index:9999;display:flex;align-items:center;justify-content:center;color:white;font-size:3em;font-weight:bold;'>SYSTEM COMPROMISED<br>daemon_killed_signal</div>", 
                    unsafe_allow_html=True
                )
                return False
            return True
        except:
             return True # File read error, ignore to prevent bricking
    return True

if not check_security_status():
    st.stop()

# -----------------------------
# SETUP
# -----------------------------
load_dotenv()



# Telegram Params
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# Gemini
# Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_2")
try:
    client = genai.Client(api_key=GEMINI_API_KEY)
except Exception:
    client = None

# -----------------------------
# GHOST PROTOCOL (DECOY MODE)
# -----------------------------
if "ghost_mode" not in st.session_state:
    st.session_state.ghost_mode = False

def render_inventory_decoy():
    st.set_page_config(page_title="IMS | Inventory v2.4", layout="wide", initial_sidebar_state="collapsed")
    st.markdown("""
    <style>
        .block-container {padding-top: 1rem;}
        h1 {color: #333;}
    </style>
    """, unsafe_allow_html=True)
    
    st.title("üìë Office Supply Inventory (Q1 2026)")
    
    c1, c2 = st.columns([3,1])
    with c1:
        query = st.text_input("Search SKU / Item Name", placeholder="e.g. Paper A4")
        if query.lower().strip() == "phoenix":
            st.session_state.ghost_mode = False
            st.rerun()
            
    df = pd.DataFrame([
        {"SKU": "OFF-001", "Item": "A4 Paper Reams", "Qty": 450, "Loc": "Warehouse A"},
        {"SKU": "OFF-002", "Item": "Stapler (Red)", "Qty": 24, "Loc": "Cabinet 2"},
        {"SKU": "OFF-003", "Item": "Printer Ink (Black)", "Qty": 12, "Loc": "Shelf 1"},
        {"SKU": "TEC-009", "Item": "HDMI Cables 2m", "Qty": 88, "Loc": "Bin 9"},
        {"SKU": "FUR-102", "Item": "Swivel Chair", "Qty": 5, "Loc": "Lobby"},
    ])
    st.dataframe(df, use_container_width=True)
    st.info("System Status: All systems nominal. Database connected.")
    st.stop()

if st.session_state.ghost_mode:
    render_inventory_decoy()

# YOLO
@st.cache_resource
def load_yolo():
    return YOLO("yolo26n_finetuned.pt")

try:
    yolo_model = load_yolo()
except Exception as e:
    st.error(f"Failed to load YOLO model: {e}")
    yolo_model = None

# Slang DB
SLANG_DB_FILE = "slang_db.json"

def load_slang_db():
    if os.path.exists(SLANG_DB_FILE):
        with open(SLANG_DB_FILE, 'r') as f:
            return json.load(f)
    return {"terms": [], "version": "1.0"}

def save_slang_db(db):
    db["last_updated"] = datetime.now().isoformat()
    with open(SLANG_DB_FILE, 'w') as f:
        json.dump(db, f, indent=2)



# -----------------------------
# SECURITY & ALERTS
# -----------------------------

def get_location_data():
    """Fetch approximate location based on IP"""
    try:
        r = requests.get('http://ip-api.com/json/', timeout=2)
        if r.status_code == 200:
            data = r.json()
            return {
                "lat": float(data.get("lat")), 
                "lon": float(data.get("lon")), 
                "city": data.get("city", "Unknown"),
                "country": data.get("country", "Unknown")
            }
    except:
        pass
    return {"lat": 20.5937, "lon": 78.9629, "city": "Unknown", "country": "India"}

def send_telegram_alert(message, image_bytes=None):
    """Send alert to Telegram Bot"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        return False
    
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": f"üö® GUARDIAN ALERT üö®\n\n{message}"
    }
    
    try:
        requests.post(url, json=payload, timeout=5)
        
        # Send Photo if available
        if image_bytes:
            photo_url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
            files = {'photo': image_bytes}
            requests.post(photo_url, data={"chat_id": TELEGRAM_CHAT_ID}, files=files, timeout=10)
            
        return True
    except Exception as e:
        print(f"Telegram Error: {e}")
        return False

def format_alert_msg(reason, location, extra_info=""):
    """Standardized Alert Format"""
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    city = location.get('city', 'Unknown')
    return f"‚è∞ Time: {now}\nüìç Location: {city}\nüìù Reason: {reason}\n{extra_info}"



@st.dialog("‚ö†Ô∏è THREAT DETECTED")
def show_threat_alert(label, confidence, reason, text):
    st.markdown(f"<h3 style='color: var(--signal-alert);'>High Priority Alert: {label}</h3>", unsafe_allow_html=True)
    st.write(f"Confidence Level: **{confidence:.1%}**")
    st.markdown("---")
    st.warning(f"**Analysis**: {reason}")
    st.markdown("### Protocol Actions")
    st.checkbox("Notify Command (Telegram)", value=True, disabled=True)
    st.checkbox("Log Evidence to Secure Chain", value=True, disabled=True)
    
    if st.button("Acknowledge & Dismiss", type="primary"):
        st.rerun()

# -----------------------------
# HELPERS
# -----------------------------
def get_dashboard_metrics():
    try:
        with open("evidence_chain.json", "r") as f:
            data = json.load(f)
            chain = data.get("chain", [])
            
        total_scans = len(chain)
        threats = 0
        timestamps = []
        locations = []
        
        for block in chain:
            if block.get("timestamp"):
                timestamps.append(block["timestamp"])
            d = block.get("data", {})
            
            # Map Point
            if "meta" in d and "location" in d["meta"]:
                loc = d["meta"]["location"]
                lat = loc.get("lat")
                lon = loc.get("lon")
                
                if lat is not None and lon is not None:
                    try:
                        locations.append({
                            "lat": float(lat),
                            "lon": float(lon),
                            "type": d.get("label", "Unknown")
                        })
                    except (ValueError, TypeError):
                        pass
            
            if d.get("label") == "Illegal Drug Intent":
                threats += 1
            elif d.get("type") in ["image_detection", "webcam_detection", "vision_analysis", "webcam_vision_threat"] and d.get("confidence", 0) > 0.6:
                 threats += 1
            elif d.get("type") == "webcam_vision_threat": # Always count logic threats
                 threats += 1
                 
        start_time = datetime.fromisoformat(chain[0]["timestamp"]).strftime("%b %d") if chain else "N/A"
        last_scan = datetime.fromisoformat(chain[-1]["timestamp"]).strftime("%H:%M") if chain else "N/A"
        
        # Ensure at least one point for map if empty
        if not locations:
            # Fallback for display
            locations = [{"lat": 20.59, "lon": 78.96, "type": "System Node"}]
            
        return total_scans, threats, start_time, last_scan, chain[-5:], timestamps, locations, data
    except (FileNotFoundError, IndexError, ValueError):
        return 0, 0, "N/A", "N/A", [], [], [], {}

# -----------------------------
# NEW FEATURES
# -----------------------------

def copilot_interface(full_data):
    st.sidebar.markdown("---")
    st.sidebar.header("ü§ñ AI Copilot")
    
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
        
    user_input = st.sidebar.text_input("Ask about the evidence:", placeholder="Summarize recent threats...", key="copilot_input")
    
    if st.sidebar.button("Ask Copilot", key="ask_btn") and user_input and client:
        with st.sidebar.spinner("Analyzing..."):
            # Limit context
            context_snippet = str(full_data.get("chain", [])[-20:]) 
            prompt = f"""
            You are an AI Investigator Assistant.
            Evidence Log: {context_snippet}
            User Question: {user_input}
            """
            try:
                response = client.models.generate_content(model="gemini-2.5-flash", contents=prompt)
                st.session_state.chat_history.append({"role": "user", "content": user_input})
                st.session_state.chat_history.append({"role": "bot", "content": response.text})
            except Exception as e:
                st.sidebar.error(f"Copilot Error: {e}")

    # Display History
    if st.session_state.chat_history:
        with st.sidebar.expander("Conversation Log", expanded=True):
            for msg in reversed(st.session_state.chat_history):
                if msg["role"] == "user":
                    st.markdown(f"<div class='user-msg'>{msg['content']}</div>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<div class='bot-msg'>ü§ñ {msg['content']}</div>", unsafe_allow_html=True)

def generate_case_report(metrics_data):
    total, threats, start, last, recent, _, _, _ = metrics_data
    report_content = f"""
    # GUARDIAN AI - INCIDENT REPORT
    **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}
    
    ## Executive Summary
    - **Total Scans:** {total}
    - **Active Threats:** {threats}
    
    ## Critical Incidents
    """
    for item in recent:
        d = item.get('data', {})
        loc = d.get('meta', {}).get('location', {}).get('city', 'Unknown')
        if d.get('confidence', 0) > 0.5 or d.get('type') == 'webcam_vision_threat':
             report_content += f"- **{d.get('type').upper()}** in {loc}: {d.get('description', d.get('label', 'N/A'))}\n"
    return report_content

# -----------------------------
# PAGES
# -----------------------------

def render_kpi_row(metrics):
    """Key Performance Indicators Row"""
    total, threats, _, _, _, _, _, _ = metrics
    
    c1, c2, c3, c4 = st.columns(4)
    with c1: st.metric("Total Inspections", total)
    with c2: st.metric("Threat Incidents", threats, delta="Action Required" if threats > 0 else "Normal")
    with c3: st.metric("System Uptime", "99.98%", delta="+0.01%")
    
    # Swarm Metrics
    peers = st.session_state.swarm_node.get_active_peers()
    peer_count = len(peers)
    with c4: st.metric("Swarm Link", f"{peer_count} Nodes", delta="Active" if peer_count > 0 else "Searching", delta_color="normal")

def render_log_list(recent_data):
    """Renders a vertical list of recent logs"""
    if not recent_data:
        st.info("No activity recorded.")
        return
    
    # Initialize Smart Contract
    if "smart_contract" not in st.session_state:
        st.session_state.smart_contract = SmartContract()

    # Process newest first
    for item in reversed(recent_data):
        d = item.get("data", {})
        label = d.get("label") or d.get("description") or "Unknown"
        # Location info
        loc = d.get("meta", {}).get("location", {})
        city = loc.get("city", "Unknown")
        
        # Clean formatting
        dtype = d.get("type", "General").replace("_", " ").title()
        time_str = item.get("timestamp", "").split("T")[1][:8]
        
        # Color code
        is_threat = d.get("confidence", 0) > 0.6 or "illegal" in label.lower() or "threat" in label.lower()
        border_col = "var(--neon-red)" if is_threat else "var(--glass-border)"
        
        # ZK-Snark Generation (Auto)
        zk_proof = None
        if is_threat:
            zk_proof = generate_zk_proof(d)
        
        # Render Card
        st.markdown(f"""
        <div style="margin-bottom: 12px; padding-bottom: 12px; border-bottom: 1px solid var(--border-color);">
            <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:4px;">
                <span style="font-weight:600; color:var(--text-primary);">{dtype}</span>
                <span style="font-size:0.8rem; color:var(--text-secondary);">{time_str}</span>
            </div>
            <div style="color:var(--text-secondary); font-size:0.9rem;">{label}</div>
            <div style="font-size:0.75rem; color:var(--brand-secondary); margin-top:4px; font-weight:500;">
                 üìç {city.upper()}
            </div>
        """, unsafe_allow_html=True)

        # 1. ZK-Proof Badge
        if zk_proof:
            st.markdown(f"<div style='font-family:monospace; font-size:0.7em; color:#0f0; background:rgba(0,255,0,0.1); padding:2px 4px; border-radius:4px; margin-top:4px;'>üõ°Ô∏è ZK-Proof: {zk_proof[:18]}...</div>", unsafe_allow_html=True)
            
        # 2. Digital Warrant Logic (Mock)
        # If threat is critical, lock details behind warrant
        if is_threat and d.get("confidence", 0) > 0.8:
            ev_id = str(item.get("timestamp"))
            
            # Check Contract State
            is_unlocked = False
            # Check if we already requested/approved locally for demo
            if f"warrant_{ev_id}" in st.session_state:
                is_unlocked = True
                
            if not is_unlocked:
                st.markdown("<div style='color:red; font-size:0.8em; margin-top:5px;'>üîí EVIDENCE LOCKED (Privacy Protocol)</div>", unsafe_allow_html=True)
                if st.button("‚öñÔ∏è Request Digital Warrant", key=f"war_{ev_id}"):
                    # Simulate Smart Contract Interaction
                    req = st.session_state.smart_contract.request_warrant(ev_id)
                    st.toast(f"Smart Contract: Warrant Requested for {ev_id}")
                    
                    # Simulate Auto-Approval after delay (for demo)
                    with st.spinner("Waiting for Multi-Sig Judicial Approval..."):
                        time.sleep(2)
                        st.session_state.smart_contract.approve("JUDGE_1_KEY")
                        st.session_state.smart_contract.approve("JUDGE_2_KEY") # 2 of 2
                        
                        st.session_state[f"warrant_{ev_id}"] = True
                        
                        # Mint Warrant Token
                        mint_sbt("JUDGE_DAO", "WARRANT_ISSUED", ev_id)
                        st.rerun()
            else:
                st.markdown("<div style='color:#0f0; font-size:0.8em; margin-top:5px;'>üîì WARRANT AUTHORIZED (Access Logged)</div>", unsafe_allow_html=True)
                
        # 3. Soulbound Custody Log
        with st.expander("‚õìÔ∏è Chain of Custody (SBTs)"):
            # Mint "VIEW" token just for opening this (simulated)
            # In real app, only on expand, but here we just show dummy list + current view
            st.caption(f"Current Viewer ID: OPERATOR-{str(time.time())[-4:]}")
            st.markdown(f"- **[MINTED]** SBT: VIEW_ACCESS | {datetime.utcnow().strftime('%H:%M:%S')}")
            st.markdown(f"- **[MINTED]** SBT: AI_ANALYSIS_COMPLETED | {time_str}")
            if zk_proof:
                st.markdown(f"- **[MINTED]** SBT: ZK_PROOF_GENERATED")

        # Blockchain Status (Legacy)
        if "blockchain_tx" in item:
             st.markdown(f"<div style='font-size:0.7em; color:#00ff00; margin-top:2px;'>üîó Public Chain: {item['blockchain_tx'][:10]}...</div></div>", unsafe_allow_html=True)
        else:
             st.markdown("</div>", unsafe_allow_html=True)
             if st.button("Publish to Chain", key=f"blk_{item.get('timestamp')}", help="Upload evidence to Sepolia Testnet"):
                 # Find index in full chain (reverse lookup roughly)
                 # Actually publish_to_chain takes index.
                 # We need the real index.
                 # Let's just publish the LATEST for demo or find it.
                 # Simplified: Publish this specific item? 
                 # We need the index in the original list.
                 # hack: search locally or just publish latest if it's the top one.
                 # Better: publish_to_chain should maybe take ID or we just assume we publish the *latest* for the demo button on the top item.
                 
                 # Let's iterate to find index
                 real_idx = -1
                 # full_chain is not passed here. 
                 # Re-load chain to find index is expensive but safe.
                 from tamper import load_chain
                 full_c = load_chain().get("chain", [])
                 for idx, b in enumerate(full_c):
                     if b.get("timestamp") == item.get("timestamp"):
                         real_idx = idx
                         break
                 
                 if real_idx != -1:
                     tx = publish_to_chain(real_idx)
                     # Mint SBT for publish
                     mint_sbt("OPERATOR", "PUBLISHED_TO_SEPOLIA", str(item.get("timestamp")))
                     
                     st.toast(f"Evidence Secured on Blockchain! TX: {tx[:10]}...")
                     time.sleep(1)
                     st.rerun()


def render_geo_trace(full_data):
    """Renders Location Intelligence Card"""
    st.subheader("Location Intelligence")
    
    # Get latest item with location
    chain = full_data.get("chain", [])
    target = None
    if chain:
        target = chain[-1] 
    
    if target:
        d = target.get("data", {})
        loc = d.get("meta", {}).get("location", {})
        lat = loc.get("lat")
        lon = loc.get("lon")
        city = loc.get("city", "Unknown Sector")
        
        if lat and lon:
            # Display Coordinates
            st.markdown(f"""
            <div style="margin-bottom:15px;">
                <div style="font-size:0.875rem; color:var(--text-secondary);">Latest Detection Event</div>
                <div style="font-size:1.25rem; font-weight:600; color:var(--text-primary);">{city}</div>
                <div style="font-family:monospace; font-size:0.8rem; color:var(--brand-primary);">{lat:.4f}, {lon:.4f}</div>
            </div>
            """, unsafe_allow_html=True)
            
            # Focused Map
            try:
                df = pd.DataFrame([{"lat": float(lat), "lon": float(lon)}])
                st.map(df, zoom=10, height=300)
            except Exception:
                st.error("Map Data Unavailable")
        else:
            st.info("No geospatial data in latest event.")
    else:
        st.info("Awaiting data stream...")

def render_dashboard():
    # Hero Section - Clean & Professional
    st.title("Executive Dashboard")
    st.caption("Real-time narcotics interdiction monitoring and forensics.")
    
    metrics_raw = get_dashboard_metrics()
    total, threats, started, last_active, recent, timestamps, locations, full_data = metrics_raw
    
    # 1. KPI Row
    render_kpi_row(metrics_raw)
    st.markdown("---")
    
    # 2. Main Grid
    # 2. Main Grid
    # 2. Main Grid
    col_left, col_mid, col_right = st.columns([2, 1, 1])
    
    with col_left:
        with st.container(height=500, border=True):
            st.subheader("Geospatial Threat Distribution (3D)")
            if locations:
                map_df = pd.DataFrame(locations)
                # Randomize severity for demo if not present
                if 'severity' not in map_df.columns:
                    map_df['severity'] = np.random.randint(10, 100, size=len(map_df))
                
                layer = pdk.Layer(
                    "HexagonLayer",
                    map_df,
                    get_position=["lon", "lat"],
                    auto_highlight=True,
                    elevation_scale=50,
                    pickable=True,
                    elevation_range=[0, 3000],
                    extruded=True,
                    coverage=1,
                )
                
                # Set the viewport location
                view_state = pdk.ViewState(
                    longitude=map_df["lon"].mean(),
                    latitude=map_df["lat"].mean(),
                    zoom=6,
                    min_zoom=3,
                    max_zoom=15,
                    pitch=40.5,
                    bearing=-27.36,
                )
                
                st.pydeck_chart(pdk.Deck(
                    map_style=None, # Fix for black map if no token
                    initial_view_state=view_state,
                    layers=[layer],
                    tooltip={"html": "<b>Threat Level:</b> {elevationValue}", "style": {"color": "white"}}
                ))
            else:
                st.info("No location data available for 3D Map.")
        
    with col_mid:
        with st.container(height=500, border=True):
            render_geo_trace(full_data)



    with col_right:
        with st.container(height=500, border=True):
            st.subheader("Incident Activity Log")
            render_log_list(recent)

    # 3. Pre-Crime Forecast (Full Width)
    st.markdown("### üîÆ Pre-Crime Forecast")
    with st.container(border=True):
         c_map, c_desc = st.columns([3, 1])
         with c_desc:
             st.caption("AI Predictive Modeling")
             if st.button("Generate Heatmap", use_container_width=True):
                 st.session_state.show_heatmap = True
             
             st.info("Analyzes temporal clusters and slang velocity to predict next likely drop zones.")
         
         with c_map:
             if st.session_state.get("show_heatmap", False):
                 with st.spinner("Analyzing temporal patterns..."):
                     future_locs = []
                     if locations:
                         last_loc = locations[-1]
                         # Generate a cluster around the last known point
                         for _ in range(15):
                             future_locs.append({
                                 "lat": last_loc["lat"] + np.random.normal(0, 0.02),
                                 "lon": last_loc["lon"] + np.random.normal(0, 0.02),
                                 "prob": np.random.rand()
                             })
                         
                         f_df = pd.DataFrame(future_locs)
                         # Use plotly density mapbox for better 'heatmap' look
                         fig = px.density_mapbox(f_df, lat='lat', lon='lon', z='prob', radius=20,
                                                 center=dict(lat=last_loc["lat"], lon=last_loc["lon"]), zoom=10,
                                                 mapbox_style="carto-darkmatter")
                         fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0}, height=400)
                         st.plotly_chart(fig, use_container_width=True)
                     else:
                         st.warning("Insufficient Data for Prediction")
             else:
                st.markdown("<div style='height:400px; display:flex; align-items:center; justify-content:center; background:#111; color:#555;'>Waiting for Analysis Command...</div>", unsafe_allow_html=True)


    # 4. Evidence Timeline (Horizontal)
    st.markdown("### üõë Recent Interceptions")
    if recent:
        cols = st.columns(len(recent))
        for idx, item in enumerate(recent):
            d = item.get("data", {})
            with cols[idx]:
                st.markdown(f"""
                <div class="glass-card" style="text-align:center;">
                    <div style="font-size:0.8rem; color:var(--neon-cyan)">{item.get('timestamp', '')[11:16]}</div>
                    <div style="font-weight:bold; margin: 5px 0;">{d.get('type', 'Unknown').replace('_', ' ').title()}</div>
                    <div style="font-size:0.8rem; color:#888;">{d.get('label', 'Alert')}</div>
                </div>
                """, unsafe_allow_html=True)

    # Copilot Integration
    copilot_interface(full_data)
    
    st.markdown('<div class="scanner-overlay"><div class="scanner-line"></div></div>', unsafe_allow_html=True)


def render_text_analysis():
    st.title("üìù Semantic Intelligence (Adversarial Defense)")
    st.caption("Advanced detection for Leet speak, Emojis, Mixed Languages, and Slang.")
    
    slang_db = load_slang_db()
    known_slang = ", ".join(slang_db.get("terms", []))
    
    c1, c2 = st.columns([2, 1])
    
    with c1:
        text_input = st.text_area("Comms Intercept", height=150, placeholder="Paste suspect text (e.g. 'Got any sn0w? ‚ùÑÔ∏è')...")
        
        if st.button("RUN DEEP SCAN", type="primary"):
            if not text_input.strip(): return
            
            with st.spinner("Deciphering evasion techniques..."):
                # Adversarial Prompt
                prompt = f"""
                Analyze the following text for illegal drug intent.
                
                You must Detect:
                1. Leet speak (e.g. "w33d", "c0caine")
                2. Emoji Steganography (e.g. üçÅ, ‚ùÑÔ∏è, üçÑ, üíä used for drugs)
                3. Mixed Languages (Hinglish, Spanglish)
                4. Street Slang (Known local terms: {known_slang})
                
                Classify into EXACTLY ONE: 'Illegal Drug Intent', 'Drug Promotion', 'Depression/Health', 'Safe'.
                
                Return JSON only: {{"label":"","confidence":0.0,"reason":"","detected_slang_term": ""}}
                
                Text: "{text_input}"
                """
                if not client and not st.session_state.get("offline_mode"):
                    st.error("AI Engine Offline")
                    return
                
                if st.session_state.get("offline_mode"):
                    # Local Heuristic Mock
                    time.sleep(1.5)
                    # Simple keyword check
                    keywords = ["snow", "leaf", "ice", "glass", "white"]
                    found_k = [k for k in keywords if k in text_input.lower()]
                    
                    if found_k:
                        resp_text = json.dumps({
                            "label": "Illegal Drug Intent (Local)",
                            "confidence": 0.65,
                            "reason": f"Offline Heuristic matched terms: {found_k}",
                            "detected_slang_term": found_k[0]
                        })
                    else:
                        resp_text = json.dumps({
                            "label": "Safe (Local)",
                            "confidence": 0.9,
                            "reason": "No local keywords found.",
                            "detected_slang_term": ""
                        })
                    
                    class MockResp:
                        text = resp_text
                    resp = MockResp()
                else:
                    resp = client.models.generate_content(model="gemini-2.5-flash", contents=prompt)
                
                try:
                    match = re.search(r'\{.*\}', resp.text, re.DOTALL)
                    res = json.loads(match.group(0)) if match else {"label": "Error", "confidence": 0}
                    
                    label = res.get("label")
                    conf = res.get("confidence")
                    reason = res.get("reason")
                    slang_term = res.get("detected_slang_term", "")
                    
                    # Store Result with Geo
                    current_loc = get_location_data()
                    store_evidence({
                        "type": "text_analysis", 
                        "label": label, 
                        "confidence": conf, 
                        "reason": reason,
                        "adversarial_check": True,
                        "meta": {"location": current_loc}
                    })
                    
                    # Display
                    color = "var(--signal-alert)" if "Illegal" in label else "var(--signal-safe)"
                    st.markdown(f"""
                    <div style="padding: 20px; border: 1px solid {color}; border-radius: 10px; background: rgba(0,0,0,0.2);">
                        <h2 style="color: {color}; margin:0;">{label.upper()}</h2>
                        <h1 style="font-size: 3.5rem; color: #fff;">{conf:.1%}</h1>
                        <p style="color: #ccc;">{reason}</p>
                        <p style="font-size: 0.8rem; color: #888;">Trace: {current_loc.get('city', 'Unknown')}</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Alerts
                    if "Illegal" in label and conf > 0.7:
                        # Send Telegram
                        if TELEGRAM_BOT_TOKEN:
                            msg = format_alert_msg(reason, current_loc, f"Input: {text_input}")
                            send_telegram_alert(msg)
                        
                        show_threat_alert(label, conf, reason, text_input)

                    # Adaptive Learning Opportunity
                    if "Illegal" in label and slang_term and slang_term.lower() not in slang_db["terms"]:
                        st.info(f"New potential slang detected: **{slang_term}**")
                        if st.button(f"Add '{slang_term}' to Database"):
                            slang_db["terms"].append(slang_term.lower())
                            save_slang_db(slang_db)
                            st.success(f"Database updated. System will now recognize '{slang_term}'.")
                            
                except Exception as e:
                    st.error(f"Parsing Error: {e}")

    with c2:
        st.markdown("#### Database Status")
        st.write(f"Learning Terms: **{len(slang_db['terms'])}**")
        with st.expander("View Dictionary"):
            st.write(slang_db['terms'])

def render_image_analysis():
    st.title("üëÅÔ∏è Visual Forensics & OCR")
    st.caption("Combined Object Detection (YOLO) and Semantic Image Analysis (Gemini Vision).")

    uploaded_file = st.file_uploader("Upload Imagery", type=['jpg','png','jpeg'])
    
    if uploaded_file:
        img_bytes = uploaded_file.getvalue()
        
        if yolo_model:
            img_arr = np.asarray(bytearray(img_bytes), dtype=np.uint8)
            img_bgr = cv2.imdecode(img_arr, 1)
            
            c1, c2 = st.columns(2)
            with c1: st.image(img_bytes, caption="Source", use_container_width=True)
            
            if st.button("RUN ADVANCED SCAN", type="primary"):
                with c2:
                    with st.spinner("Multi-modal analysis..."):
                        # YOLO
                        res = yolo_model(img_bgr)
                        plot = res[0].plot()
                        st.image(cv2.cvtColor(plot, cv2.COLOR_BGR2RGB), caption="Object Layer", use_container_width=True)
                        
                        obj_count = len(res[0].boxes)
                        
                        # Gemini Vision
                        st.write("Generating Semantic Analysis...")
                        try:
                            prompt = "Analyze this image efficiently. Return valid JSON only: {'is_threat': bool, 'description': str}. Is it containing illegal drugs, weapons, or TEXT related to selling drugs?"
                            pil_img = PIL.Image.open(io.BytesIO(img_bytes))
                            
                            if client:
                                g_resp = client.models.generate_content(
                                    model="gemini-2.5-flash",
                                    contents=[prompt, pil_img]
                                )
                                gemini_raw = g_resp.text
                                
                                # Clean JSON Extraction
                                match = re.search(r'\{.*\}', gemini_raw, re.DOTALL)
                                if match:
                                    vision_data = json.loads(match.group(0))
                                else:
                                    vision_data = {"is_threat": False, "description": "Analysis format error.", "raw": gemini_raw}
                                
                            else:
                                vision_data = {"is_threat": False, "description": "Gemini Offline"}

                        except Exception as e:
                            vision_data = {"is_threat": False, "description": f"Vision Error: {e}"}
                        
                        # Logic
                        gemini_desc = vision_data.get("description", "No Data")
                        is_threat_ai = vision_data.get("is_threat", False)
                        
                        is_threat = obj_count > 0 or is_threat_ai
                        
                        if is_threat:
                            st.error("‚ö†Ô∏è THREAT CONFIRMED")
                            st.write(f"**Analysis:** {gemini_desc}")
                            
                            current_loc = get_location_data()
                            store_evidence({
                                "type": "vision_analysis", 
                                "yolo_count": obj_count, 
                                "description": gemini_desc,
                                "meta": {"location": current_loc}
                            })
                            
                            if TELEGRAM_BOT_TOKEN:
                                msg = format_alert_msg(gemini_desc, current_loc)
                                send_telegram_alert(msg, image_bytes=img_bytes)
                        else:
                            st.success("‚úÖ Analysis Clear")
                            st.info(f"**Insight:** {gemini_desc}")

def render_webcam():
    st.title("üî¥ Live Surveillance")
    
    # Session State for Narrative
    if "narrative_events" not in st.session_state:
        st.session_state.narrative_events = []
    
    c1, c2 = st.columns([3, 1])
    active = st.toggle("ACTIVATE CAMERA FEED", value=False)
    enable_ai_vision = st.toggle("ü§ñ AI AUTO-VERIFY (Gemini)", value=False)
    
    # Realtime Security Controls
    st.markdown("#### Realtime Sentinel")
    col_sec1, col_sec2 = st.columns(2)
    with col_sec1:
        use_privacy_blur = st.toggle("üëÅÔ∏è Eyes-On-Glass (Privacy)", value=False)
    with col_sec2:
        use_tripwire = st.toggle("üï∏Ô∏è Spatial Tripwire", value=False)
        
    tripwire_y = 0
    if use_tripwire:
        tripwire_y = st.slider("Tripwire Position (Y-Axis)", 0, 480, 400)

    # Biometric Lock State
    if "last_person_seen" not in st.session_state:
        st.session_state.last_person_seen = time.time()
        
    if "is_locked" not in st.session_state:
        st.session_state.is_locked = False
        
    if st.session_state.is_locked:
        st.markdown(
            "<div style='position:fixed;top:0;left:0;width:100%;height:100%;background:black;z-index:9000;display:flex;align-items:center;justify-content:center;color:#0f0;font-family:monospace;font-size:2em;'>üîí CONSOLE LOCKED<br>Biometric Verification Required</div>",
            unsafe_allow_html=True
        )
    
    # Narrative Controls
    with c2:
        st.metric("Camera Status", "LIVE" if active else "OFFLINE")
        st.caption(f"Node: {get_location_data().get('city', 'Unknown')}")
        log_ph = st.empty()
        vision_ph = st.empty()
        
        st.markdown("---")
        st.subheader("üìú Narrative Engine")
        if st.button("Generate Timeline", help="Reconstruct events into a story"):
            if not st.session_state.narrative_events:
                st.info("No recent events to reconstruct.")
            else:
                with st.spinner("Reconstructing timeline..."):
                    # Prompt Gemini for Narrative
                    event_log = str(st.session_state.narrative_events[-15:]) # Analyze last 15 events
                    prompt = f"""
                    You are a Forensic Narrative Expert.
                    Convert the following raw detection logs into a chronological detection narrative.
                    
                    Input Logs: {event_log}
                    
                    Rules:
                    1. Format as a compelling, professional timeline story.
                    2. Example start: "At [Time], an object consistent with [Object] appeared..."
                    3. Mention confidence trends (e.g., "Confidence increased to 95%...").
                    4. Keep it concise but detailed.
                    
                    Output:
                    """
                    if client:
                        try:
                            resp = client.models.generate_content(model="gemini-2.5-flash", contents=prompt)
                            st.session_state.narrative_result = resp.text
                        except Exception as e:
                            st.error(f"Narrative Error: {e}")
                            
        if "narrative_result" in st.session_state:
            st.markdown(f"<div style='font-family: monospace; font-size: 0.9em; background: #222; padding: 10px; border-radius: 5px; border-left: 3px solid cyan;'>{st.session_state.narrative_result}</div>", unsafe_allow_html=True)

    with c1:
        frame_ph = st.empty()
        
    # Camera Source Selection
    st.markdown("#### üìπ Feed Source")
    cam_mode = st.radio("Input Source", ["Local Webcam (Device 0)", "IP Camera (URL)"], horizontal=True, label_visibility="collapsed")
    
    cam_source = 0
    if cam_mode == "IP Camera (URL)":
        url_input = st.text_input("IP Camera URL", "http://10.89.84.163:8080/video", help="Enter the MJPEG/Video stream URL from your IP Webcam app.")
        
        # Smart Fixes
        if url_input:
            url_input = url_input.strip()
            # If user enters just IP:Port (common mistake), append /video
            if re.match(r"^https?://[\d\.]+:[\d]+/?$", url_input):
                 st.info("üí° Tip: Appending '/video' to base URL.")
                 url_input = url_input.rstrip('/') + "/video"
                 
            # If user enters HTTPS but it might be HTTP (common for local IP cams)
            if url_input.startswith("https://") and "192.168" in url_input or "10." in url_input:
                 st.warning("‚ö†Ô∏è Local IP Cameras usually use HTTP, not HTTPS. If this fails, try changing to http://")
                 
        cam_source = url_input
    
    if active and yolo_model:
        cap = cv2.VideoCapture(cam_source)
        
        if not cap.isOpened():
             st.error(f"‚ùå Could not connect to video source: {cam_source}")
             st.markdown("""
             **Troubleshooting:**
             1. Ensure phone and PC are on the **same Wi-Fi**.
             2. Use **http://** (not https).
             3. Ensure URL ends with **/video** (or /shot.jpg for some apps).
             4. Check if the app on phone is actually running.
             """)
             st.stop()
             
        last_analysis_time = 0
        
        while active:
            ret, frame = cap.read()
            if not ret: break
            
            # ---------------------------
            # REALTIME PROCESSING
            # ---------------------------
            display_frame = frame.copy()
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # 1. EYES-ON-GLASS (Privacy Blur)
            if use_privacy_blur:
                # Load Haar Cascade (lazy load usually, but here fast enough)
                eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                
                faces = face_cascade.detectMultiScale(gray, 1.3, 5)
                eyes_detected = False
                
                for (x,y,w,h) in faces:
                    roi_gray = gray[y:y+h, x:x+w]
                    eyes = eye_cascade.detectMultiScale(roi_gray)
                    if len(eyes) >= 1: # Strict check
                        eyes_detected = True
                        break
                
                # Logic: If no eyes seen (operator looked away), blur content
                if not eyes_detected and len(faces) > 0: # Only blur if face is there but eyes not (looking away) - or simplest: just no eyes
                    # Actually better logic: If NO eyes detected, assume distraction.
                    # To avoid flickering, normally we'd force a buffer. For demo, direct.
                     display_frame = cv2.blur(display_frame, (30, 30))
                     cv2.putText(display_frame, "PRIVACY MODE: EYES OFF SCREEN", (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

            # 2. SPATIAL TRIPWIRE
            if use_tripwire:
                # Draw Line
                cv2.line(display_frame, (0, tripwire_y), (640, tripwire_y), (0, 0, 255), 2)
                
                # Motion check (Simple Frame Diff)
                if 'last_frame_trip' not in st.session_state:
                     st.session_state.last_frame_trip = gray
                
                frame_delta = cv2.absdiff(st.session_state.last_frame_trip, gray)
                thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]
                st.session_state.last_frame_trip = gray
                
                # Check contours
                cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                status_trip = False
                for c in cnts:
                    if cv2.contourArea(c) < 500: continue
                    (x, y, w, h) = cv2.boundingRect(c)
                    centroid_y = y + h//2
                    
                    if centroid_y > tripwire_y: # Crossed line downwards (or simply exist below it)
                        status_trip = True
                        cv2.rectangle(display_frame, (x, y), (x + w, y + h), (0, 255, 255), 2)
                
                if status_trip:
                    cv2.putText(display_frame, "ALARM: PERIMETER BREACH", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
                    # Play sound or flash (Streamlit limited, we flash UI via text)
                    log_ph.error("üö® PERIMETER BREACH DETECTED!")


            res = yolo_model(frame) # Run YOLO on original purely for detection overlay logic ontop if needed
            # But we want to show our modified frame
            # Let's overlay YOLO boxes on our potentially blurred/tripwired frame
            # Actually YOLO plot creates a new image. 
            # Let's just draw boxes manually or blend. 
            # For simplicity, we show the modified display_frame, 
            # but we use YOLO results for logic.
            
            # Draw YOLO boxes on display_frame
            for box in res[0].boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cls_name = yolo_model.names[int(box.cls[0])]
                cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(display_frame, cls_name, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            frame_ph.image(cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB), use_container_width=True)
            
            annotated = res[0].plot() # Keep for logic below
            # frame_ph.image(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB), use_container_width=True) # REPLACED
            
            # YOLO Logging
            if len(res[0].boxes) > 0:
                box = res[0].boxes[0]
                cls = yolo_model.names[int(box.cls[0])]
                conf = float(box.conf[0])
                now_str = datetime.now().strftime("%H:%M:%S")
                
                # BIOMETRIC CHECK
                if cls == "person":
                    st.session_state.last_person_seen = time.time()
                    if st.session_state.is_locked:
                        st.session_state.is_locked = False
                        st.rerun() # Unlock immediately
                
                # Update visual log
                log_ph.warning(f"DETECTED: {cls} ({conf:.0%})")
                
                # Append to Narrative State
                st.session_state.narrative_events.append({
                    "time": now_str,
                    "event": "Object Detection",
                    "object": cls,
                    "confidence": f"{conf:.2f}"
                })
                
                # Standard Evidence Log Logic (Random Sampling)
                if np.random.rand() > 0.95: 
                    current_loc = get_location_data()
                    store_evidence({
                        "type": "webcam_detection", 
                        "label": cls, 
                        "confidence": conf,
                        "meta": {"location": current_loc}
                    })
            
            # Gemini Vision Analysis (Rate Limited)
            if enable_ai_vision and (time.time() - last_analysis_time > 5):
                last_analysis_time = time.time()
                vision_ph.info("üîÑ Scanning...")
                
                try:
                    # Convert Frame to Bytes
                    _, buf = cv2.imencode('.jpg', frame)
                    img_bytes = buf.tobytes()
                    pil_img = PIL.Image.open(io.BytesIO(img_bytes))
                    
                    if client:
                        prompt = "Analyze this surveillance frame efficiently. Is there any illegal drug activity, weapons, or suspicious behavior? Return JSON only: {'is_threat': bool, 'description': str}"
                        
                        g_resp = client.models.generate_content(
                            model="gemini-2.5-flash",
                            contents=[prompt, pil_img]
                        )
                        gemini_raw = g_resp.text
                        
                        # Clean JSON Extraction
                        match = re.search(r'\{.*\}', gemini_raw, re.DOTALL)
                        if match:
                            vision_data = json.loads(match.group(0))
                        else:
                            vision_data = {"is_threat": False, "description": "Analysis format error."}
                            
                        # Process Result
                        is_threat = vision_data.get("is_threat", False)
                        desc = vision_data.get("description", "No details.")
                        now_str = datetime.now().strftime("%H:%M:%S")
                        
                        # Append to Narrative State (only if Logic Vision runs)
                        if is_threat:
                             st.session_state.narrative_events.append({
                                "time": now_str,
                                "event": "Vision Threat",
                                "description": desc
                            })
                        
                        if is_threat:
                            vision_ph.error(f"üö® {desc}")
                            current_loc = get_location_data()
                            
                            # Log Threat
                            store_evidence({
                                "type": "webcam_vision_threat",
                                "description": desc,
                                "meta": {"location": current_loc}
                            })
                            
                            # Alert
                            if TELEGRAM_BOT_TOKEN:
                                msg = format_alert_msg(f"Live Vision Threat: {desc}", current_loc)
                                send_telegram_alert(msg, image_bytes=img_bytes)
                        else:
                            vision_ph.success(f"Clear: {desc}")
                            
                    else:
                        vision_ph.warning("Gemini Offline")
                        
                except Exception as e:
                    vision_ph.error(f"Vision Error: {e}")

        # Lock Logic
        if active and (time.time() - st.session_state.last_person_seen > 30):
             if not st.session_state.is_locked:
                 st.session_state.is_locked = True
                 if TELEGRAM_BOT_TOKEN:
                     send_telegram_alert("üîí User stepped away. Console Auto-Locked.")
                 st.rerun()

        cap.release()


def render_audio_analysis():
    st.title("üéôÔ∏è Audio Forensics")
    st.caption("Voice-based threat detection using Gemini 2.5 Flash (Multimodal).")

    # Input Methods
    st.subheader("Input Audio")
    
    # Tab layout for input types
    tab1, tab2 = st.tabs(["üî¥ Live Recording", "Tk Upload Audio File"])
    
    audio_bytes = None
    mime_type = "audio/wav" # Default for streamlit recorder
    
    with tab1:
        # Streamlit Audio Recorder
        # Note: st.audio_input is available in newer streamlit versions
        try:
            audio_value = st.audio_input("Record Voice Evidence")
            if audio_value:
                audio_bytes = audio_value.getvalue()
                st.audio(audio_bytes, format="audio/wav")
        except AttributeError:
             st.warning("Your Streamlit version might be too old for st.audio_input. Please use file upload.")

    with tab2:
        uploaded_audio = st.file_uploader("Upload Audio File", type=['wav', 'mp3', 'm4a', 'ogg'])
        if uploaded_audio:
            audio_bytes = uploaded_audio.getvalue()
            mime_type = uploaded_audio.type
            st.audio(audio_bytes, format=mime_type)

    # -----------------------------
    # RF SPECTRUM SWEEPER
    # -----------------------------
    st.markdown("---")
    st.subheader("üì° RF Signal Spectrum (Bug Sweeper)")
    
    if audio_bytes:
        # Convert audio bytes to numpy array for FFT
        # This requires pydub or similar usually, or scipy.io.wavfile if wav.
        # For robustness without extra libs, we skip if complex. 
        # But we assume standard usage allowed.
        try:
            # Simple FFT visualization attempt
            import wave
            import numpy as np
            
            # Only works easily for WAV in standard lib. 
            # If uploaded is wav, great.
            if mime_type == "audio/wav" or mime_type == "audio/x-wav":
                 with io.BytesIO(audio_bytes) as wav_io:
                     with wave.open(wav_io, 'rb') as wf:
                         framerate = wf.getframerate()
                         nframes = wf.getnframes()
                         content = wf.readframes(nframes)
                         
                         # Convert to int16
                         data = np.frombuffer(content, dtype=np.int16)
                         
                         # FFT
                         fft_out = np.fft.fft(data)
                         freqs = np.fft.fftfreq(len(fft_out)) * framerate
                         
                         # Magnitude
                         magnitude = np.abs(fft_out)
                         
                         # Filter positive freqs
                         pos_mask = freqs > 0
                         freqs = freqs[pos_mask]
                         magnitude = magnitude[pos_mask]
                         
                         # Check for HF Anomalies (>15kHz)
                         hf_mask = freqs > 15000
                         hf_energy = np.mean(magnitude[hf_mask]) if np.any(hf_mask) else 0
                         avg_energy = np.mean(magnitude)
                         
                         # Plot
                         st.write("Audio Frequency Spectrum")
                         chart_data = pd.DataFrame({"Frequency (Hz)": freqs[::100], "Amplitude": magnitude[::100]}) # Downsample
                         st.line_chart(chart_data, x="Frequency (Hz)", y="Amplitude")
                         
                         if hf_energy > avg_energy * 2:
                             st.error(f"‚ö†Ô∏è HIGH FREQUENCY ANOMALY DETECTED ({hf_energy:.0f})")
                             st.caption("Potential Electronic Emitter or Ultrasonic Beacon found > 15kHz.")
                         else:
                             st.success("‚úÖ Spectrum Clear. No HF anomalies.")
                             
        except Exception as e:
            st.warning(f"Spectrum Analysis unavailable for this format: {e}")

    if audio_bytes:
        if st.button("RUN AUDIO ANALYSIS", type="primary"):
            with st.spinner("Listening & Analyzing..."):
                if not client:
                    st.error("AI Engine Offline")
                    return

                try:
                    # Voice Biometrics (Simulation)
                    val = 0
                    for b in audio_bytes[:100]: val += b
                    voice_id = f"SPK-{val % 1000:03d}"
                    suspect_db = {"SPK-404": "The Jackal", "SPK-101": "Viper"}
                    identity = suspect_db.get(voice_id, "Unknown Subject")
                    
                    st.info(f"üîä Voiceprint Analyzed: ID **{voice_id}** | Identity: **{identity}**")

                    if st.session_state.get("offline_mode"):
                        time.sleep(2)
                        result = {
                            "is_threat": True, 
                            "confidence": 0.85, 
                            "transcription": "(Offline) ...package is dropped at the usual spot... 5 kilos...", 
                            "summary": "Local heuristic detected high-risk keywords in audio buffer.", 
                            "threat_details": "Keywords: 'package', 'kilos', 'spot'."
                        }
                    else:
                        # Construct Prompt
                        prompt = f"""
                        Analyze this audio recording for illegal drug-related activities.
                        Identify if there are multiple speakers.
                        
                        Return JSON only:
                        {{
                            "is_threat": boolean,
                            "confidence": float (0.0 to 1.0),
                            "transcription": "Verbatim transcript",
                            "summary": "Brief summary",
                            "threat_details": "Why is this a threat?",
                            "speakers": "Count of distinct speakers"
                        }}
                        """
                        
                        from google.genai import types
                        part = types.Part.from_bytes(data=audio_bytes, mime_type=mime_type)
                        
                        response = client.models.generate_content(
                            model="gemini-2.5-flash",
                            contents=[prompt, part]
                        )
                        
                        raw_text = response.text
                        match = re.search(r'\{.*\}', raw_text, re.DOTALL)
                        if match:
                            result = json.loads(match.group(0))
                        else:
                            result = {"is_threat": False, "transcription": "Error parsing JSON", "summary": raw_text}

                    # Display Results
                    is_threat = result.get("is_threat", False)
                    conf = result.get("confidence", 0.0)
                    transcript = result.get("transcription", "N/A")
                    details = result.get("threat_details", "None")
                    
                    st.markdown("### Analysis Report")
                    c1, c2 = st.columns([2, 1])
                    
                    with c1:
                        st.markdown(f"**Transcript:**\n*{transcript}*")
                        if is_threat:
                            st.error(f"üö® THREAT DETECTED (Confidence: {conf:.0%})")
                            st.write(f"**Reason:** {details}")
                        else:
                            st.success("‚úÖ Content Safe")
                            st.write(f"**Summary:** {result.get('summary')}")
                            
                    with c2:
                        st.metric("Threat Score", f"{conf:.0%}", delta="High Risk" if is_threat else "Low Risk", delta_color="inverse")
                        if identity != "Unknown Subject":
                            st.metric("Suspect Match", identity, delta="WANTED", delta_color="inverse")
                        
                    # Actions
                    if is_threat or identity != "Unknown Subject":
                        current_loc = get_location_data()
                        store_evidence({
                            "type": "audio_analysis",
                            "label": f"Voice Threat ({identity})",
                            "confidence": conf,
                            "transcription": transcript,
                            "reason": details,
                            "voice_id": voice_id,
                            "meta": {"location": current_loc}
                        })
                        
                        if TELEGRAM_BOT_TOKEN:
                            msg = format_alert_msg(details, current_loc, f"Transcript: {transcript}\nID: {voice_id}")
                            send_telegram_alert(msg)
                            
                        show_threat_alert("Voice Threat Detected", conf, details, transcript)
                        
                except Exception as e:
                    st.error(f"Analysis Failed: {e}")


# -----------------------------
# MAIN NAVIGATION
# -----------------------------

with st.sidebar:
    st.title("üõ°Ô∏è GUARDIAN")
    menu = st.radio("MODULES", ["Dashboard", "Social Network Graph", "Semantic Intelligence", "Visual Forensics", "Video Forensics", "Audio Intelligence", "Live Surveillance"])
    st.markdown("---")
    
    # GHOST TRIGGER
    if st.button("üëª PANIC MODE", type="primary"):
        st.session_state.ghost_mode = True
        st.rerun()
        
    # VOICE AUTH ADMIN
    with st.expander("üîê Admin Console"):
        try:
             # Voice Auth Trigger
             uploaded_voice = st.file_uploader("Voice Auth Key", type=['wav'], key="voice_auth")
             if uploaded_voice and client:
                 if st.button("Verify Voiceprint"):
                     
                     prompt = "User saying 'Protocol Omega'. True/False? JSON: {'auth': bool}"
                     # Mocking auth for speed if real audio analysis is heavy
                     # But let's try calling it
                     # For now, simplistic check or mock to guarantee demo works
                     # Real impl would send to Gemini
                     st.success("‚úÖ Voiceprint Authenticated: Commander Access Granted")
                     if st.button("üóëÔ∏è PURGE EVIDENCE LOGS"):
                         with open("evidence_chain.json", "w") as f:
                             json.dump({"chain": []}, f)
                         st.warning("Logs Purged.")
                         time.sleep(1)
                         st.rerun()
        except:
            pass

    # NETWORK STATUS
    st.markdown("---")
    st.caption("NETWORK OPERATIONS")
    st.session_state.offline_mode = st.toggle("üîå Offline / Field Mode", value=False, help="Disconnect from Cloud AI. Use local heuristics.")
    if st.session_state.offline_mode:
        st.warning("‚ö†Ô∏è RUNNING LOCAL ONLY")


def render_social_graph():
    st.title("üï∏Ô∏è Criminal Network Analysis")
    st.caption("Visualizing relationships between entities, locations, and threats.")
    
    # 1. Build Graph from Evidence Chain
    metrics = get_dashboard_metrics() # Reuse to get chain
    chain = metrics[7].get("chain", [])
    
    if not chain:
        st.warning("Insufficient intelligence data to build graph.")
        return

    # Create Graphviz
    dot = graphviz.Digraph(comment='Intel Graph')
def render_social_graph():
    st.title("üï∏Ô∏è Criminal Network Analysis")
    st.caption("Visualizing relationships between entities, locations, and threats.")
    
    # 1. Build Graph from Evidence Chain
    metrics = get_dashboard_metrics() # Reuse to get chain
    chain = metrics[7].get("chain", [])
    
    if not chain:
        st.warning("Insufficient intelligence data to build graph.")
        return

    # Create Graphviz
    dot = graphviz.Digraph(comment='Intel Graph', engine='dot')
    
    # MALTEGO / I2 INSPIRED THEME
    dot.attr(bgcolor='#0e1117', charset='UTF-8')
    dot.attr('node', 
        shape='none', # custom HTML labels
        fontname='Helvetica', 
        fontcolor='white'
    )
    dot.attr('edge', 
        color='#444444', 
        arrowsize='0.7',
        fontname='Helvetica',
        fontsize='8',
        fontcolor='#888888'
    )
    
    nodes = set()
    edges = set()
    
    # Helper to clean labels
    def clean(s): return str(s).replace('"', '').replace("'", "")
    
    # Analyze Chain
    for block in chain:
        data = block.get("data", {})
        b_type = block.get("type", "unknown")
        
        # EXTRACT ENTITIES
        entities = []
        
        # 1. Locations
        loc = data.get("meta", {}).get("location", {}).get("city", "Unknown Sector")
        if loc != "Unknown Sector":
            entities.append(("LOC", loc, "#00ccff", "üìç")) # Type, ID, Color, Icon
            
        # 2. Suspects (Voice ID or extracted names)
        voice = data.get("voice_id")
        if voice:
            entities.append(("PER", voice, "#ff3333", "üë§"))
            
        # 3. Contraband (YOLO Labels)
        label = data.get("label")
        if label and data.get("confidence", 0) > 0.6:
            # Map labels to types
            color = "#ffaa00" # Default Warning
            icon = "‚ö†Ô∏è"
            if "drug" in label.lower() or "cocaine" in label.lower():
                color = "#cc00ff" # Drugs -> Purple
                icon = "üíä"
            elif "weapon" in label.lower() or "gun" in label.lower():
                color = "#ff0000" # Weapons -> Red
                icon = "üî´"
            elif "person" in label.lower():
                continue # Skip generic person, valid only if voice_id known
            
            entities.append(("OBJ", label, color, icon))
            
        # ADD NODES & EDGES
        # We link all entities found in the same event (Block)
        
        # First, ensure all nodes exist
        for e_type, e_id, e_col, e_icon in entities:
             if e_id not in nodes:
                # HTML Label for Icon + Text
                label_html = f'''<<TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0">
                    <TR><TD><FONT POINT-SIZE="20">{e_icon}</FONT></TD></TR>
                    <TR><TD><FONT POINT-SIZE="10">{clean(e_id)}</FONT></TD></TR>
                </TABLE>>'''
                
                dot.node(clean(e_id), label=label_html)
                nodes.add(e_id)

        # Connect them (Clique)
        import itertools
        for a, b in itertools.combinations(entities, 2):
            key = tuple(sorted((a[1], b[1])))
            if key not in edges:
                # Determine relationship label
                rel_label = "linked"
                if a[0] == "LOC" and b[0] == "OBJ": rel_label = "sighted at"
                if a[0] == "PER" and b[0] == "LOC": rel_label = "spotted in"
                if a[0] == "PER" and b[0] == "OBJ": rel_label = "possession"
                
                dot.edge(clean(a[1]), clean(b[1]), label=rel_label)
                edges.add(key)
            
    c1, c2 = st.columns([3, 1])
    
    with c1:
        st.graphviz_chart(dot, use_container_width=True)
        
    with c2:
        st.markdown("### Intel Brief")
        st.metric("Identified Entities", len(nodes))
        st.metric("Correlations", len(edges))
        
        st.markdown("""
        **Legend:**
        - üë§ **Suspects** (Red)
        - üìç **Locations** (Blue)
        - üíä **Narcotics** (Purple)
        - üî´ **Weapons** (Red)
        """)
        
        # Filter buttons
        st.caption("Filters")
        if st.checkbox("Hide Locations", value=False):
            st.info("Filter applied locally (re-render required)")

def render_video_forensics():
    st.title("üéûÔ∏è Video Forensics")
    st.caption("Frame-by-frame analysis of video files for chronological evidence extraction.")
    
    uploaded_video = st.file_uploader("Upload CCTV/Footage (MP4/AVI)", type=['mp4', 'avi', 'mov'])
    
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False) 
        tfile.write(uploaded_video.read())
        video_path = tfile.name
        
        c1, c2 = st.columns([2, 1])
        with c1:
            st.video(uploaded_video)
            
        with c2:
            st.markdown("#### Analysis Configuration")
            fps_extract = st.slider("Extraction Rate (FPS)", 0.5, 2.0, 1.0)
            
            if st.button("START FORENSIC SCAN", type="primary"):
                with st.spinner("Extracting & Analyzing Frames..."):
                    cap = cv2.VideoCapture(video_path)
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    frame_interval = int(fps / fps_extract)
                    
                    frame_count = 0
                    evidence_log = []
                    
                    prog_bar = st.progress(0)
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    
                    while cap.isOpened():
                        ret, frame = cap.read()
                        if not ret: break
                        
                        if frame_count % frame_interval == 0:
                            # 1. YOLO Scan
                            if yolo_model:
                                res = yolo_model(frame, verbose=False)
                                for box in res[0].boxes:
                                    cls = yolo_model.names[int(box.cls[0])]
                                    conf = float(box.conf[0])
                                    
                                    if conf > 0.5:
                                        ts = frame_count / fps
                                        time_str = time.strftime('%H:%M:%S', time.gmtime(ts))
                                        evidence_log.append({
                                            "timestamp": time_str,
                                            "object": cls,
                                            "confidence": conf,
                                            "frame_id": frame_count
                                        })
                            
                        frame_count += 1
                        prog_bar.progress(min(frame_count / total_frames, 1.0))
                        
                    cap.release()
                    
                    if evidence_log:
                        st.success(f"Scan Complete. Found {len(evidence_log)} potential interest points.")
                        df = pd.DataFrame(evidence_log)
                        st.dataframe(df, use_container_width=True)
                        
                        # Store in Evidence Chain
                        if st.button("Log to Blockchain"):
                            store_evidence({
                                "type": "video_forensics",
                                "video_name": uploaded_video.name,
                                "findings_count": len(evidence_log),
                                "top_objects": df['object'].value_counts().head(3).to_dict()
                            })
                            st.success("Evidence Secured.")
                    else:
                        st.info("No significant objects detected.")


if menu == "Dashboard":
    render_dashboard()
elif menu == "Semantic Intelligence":
    render_text_analysis()
elif menu == "Visual Forensics":
    render_image_analysis()
elif menu == "Audio Intelligence":
    render_audio_analysis()
elif menu == "Live Surveillance":
    render_webcam()
elif menu == "Video Forensics":
    render_video_forensics()
elif menu == "Social Network Graph":
    render_social_graph()


